{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564bca8e",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai faiss-cpu tiktoken sentence-transformers PyMuPDF ipywidgets deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2baf2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f5d5e",
   "metadata": {},
   "source": [
    "# PDF faylni yuklab, hujjatni chunklash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d2c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 ta sahifa yuklandi.\n",
      "JO N A V A R R O\n",
      "SIZ\n",
      "NIMANI 0â€˜YLASANGIZ\n",
      "MEN\n",
      "0â€˜SHANI KO'RAMAN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 PDF faylni yuklash va matnga aylantirish\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PDF fayl nomi\n",
    "pdf_path = \"data/book_1.pdf\"\n",
    "\n",
    "# Hujjatni yuklash\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"{len(documents)} ta sahifa yuklandi.\")\n",
    "print(documents[0].page_content[:300])  # 1-sahifadan parchani chiqaramiz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8a62cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132 ta chunk tayyor boâ€˜ldi.\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Chunklash (matnni boâ€˜laklarga ajratish)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Chunking parametrlar\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"{len(chunks)} ta chunk tayyor boâ€˜ldi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e05344",
   "metadata": {},
   "source": [
    "# Embedding + FAISS Index yaratish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0af975a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Embedding modelini chaqirish\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedding modeli\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    # model_name=\"intfloat/multilingual-e5-small\"\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" \n",
    ") #or sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "# --------------- Ollama Embeddings ----------------\n",
    "# Agar Ollama embeddings ishlatmoqchi bo'lsangiz, quyidagi kodni\n",
    "# faqat Ollama o'rnatilgan bo'lsa ishlating:\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d45c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 FAISS bazaga joylash\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# FAISS vektor bazasini yaratish\n",
    "vector_db = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# Localga saqlash (keyingi bosqichda foydalanamiz)\n",
    "vector_db.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770bcc8b",
   "metadata": {},
   "source": [
    "# Retrieverni sozlash va LLM bilan birlashtirish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da4c7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 FAISS indexâ€™ni yuklash\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Oldin saqlangan bazani yuklaymiz\n",
    "vector_db = FAISS.load_local(\"faiss_index\", embedding_model)\n",
    "\n",
    "# Retriever obyektini yasaymiz\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 OpenAI LLM modelini sozlash\n",
    "\n",
    "# from langchain.llms import OpenAI\n",
    "\n",
    "# import os\n",
    "\n",
    "# # OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-***\"  # <-- bu yerga oâ€˜zingizning API keyâ€™ingizni qoâ€˜ying. (pullik)\n",
    "\n",
    "# # LLM ni ishga tushuramiz (GPT-3.5)\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# -------------------- Agar Ollama ishlatmoqchi bo'lsangiz --------------------\n",
    "# Ollama modelini yuklab olish\n",
    "# ollama run llama3 or (mistral)\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ded6e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template=\"\"\"\n",
    "You are an intelligent AI assistant helping a user who speaks English.\n",
    "The user will ask you a question, and you should provide a clear, concise, and reliable answer based on the following context.\n",
    "Answer the question based only on the context below.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "ðŸ“š Context:\n",
    "{context}\n",
    "\n",
    "â“ Question: {question}\n",
    "\n",
    "ðŸ¤– Answer:\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d43ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CombineDocumentsChain ichida ishlat\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "qa_prompt_chain = LLMChain(llm=llm, prompt=custom_prompt)\n",
    "\n",
    "combine_docs_chain = StuffDocumentsChain(\n",
    "    llm_chain=qa_prompt_chain,\n",
    "    document_variable_name=\"context\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c815ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 RAG chain yaratamiz\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     retriever=retriever,\n",
    "#     return_source_documents=True\n",
    "# )\n",
    "\n",
    "qa_chain = RetrievalQA(\n",
    "    retriever=retriever,\n",
    "    combine_documents_chain=combine_docs_chain,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b822603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translator\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_text(txt_input, source='uz', target='en'):\n",
    "    \"\"\"\n",
    "    Translate text from Uzbek to English.\n",
    "    \"\"\"\n",
    "    input_english = GoogleTranslator(source=source, target=target).translate(txt_input)\n",
    "    return input_english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f76dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ Savol: Qanday yolgâ€˜onni aniqlash mumkin?\n",
      "ðŸ”„ Ingliz tiliga tarjima: What lies can be determined?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Javob o'zbek tilida:\n",
      "\n",
      " Taqdim etilgan kontekst asosida, matn yolg'on va yolg'onni aniqlash usullarini muhokama qilmoqda. Muallif kimningdir haqiqatni aytayotgan yoki yo'qligini aniqlashga urinayotganda noilojma inshootlari va xatti-harakatlariga e'tibor berish muhimligini ta'kidlaydi.\n",
      "\n",
      "Shu nuqtai nazardan, sizning savolingizga javob: \"Yolgun Fosh Qiluvchi Savollar Berish Kerak\" deb tarjima qilinadi, bu \"siz yolg'onni ochib beradigan savollarni berishingiz kerak\" deb tarjima qilinadi.\n",
      "\n",
      "ðŸ“– Manbalar:\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 63\n",
      "Matn:\n",
      " qilish yoki aytilmay yashirishga harakat qilinayotgan \n",
      "xabami aniqlashda yordam beradi.\n",
      "Mening fikrimcha, haqqoniy maâ€™lumot olishga uri- \n",
      "nishdan koâ€˜ra, tinchlantiruvchi harakatni kuzatish ter-\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 288\n",
      "Matn:\n",
      " kuzatish kerak.\n",
      "Yolgâ€˜onni fosh qiluvchi savollar berish kerak. Bundan \n",
      "tashqari, imkoni boricha noverbal xabarlami koâ€˜proq \n",
      "yigâ€˜ishingiz kerak. Siz qancha atvor bogâ€˜lanishlarini topa \n",
      "olsangiz, kuzatishingiz natijasida shuncha ishonch komil\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 35\n",
      "Matn:\n",
      " uchun nimaga eâ€™tibor qilish zarurligini anglab yetasiz. \n",
      "Bundan foydalanib, oila aâ€™zolaringiz, sevimli inson, hatÂ­\n",
      "to begona kishini ham oldindan oâ€˜qiy olishingiz mumkin \n",
      "boâ€˜ladi. Bundan tashqari, noverbal atvoming fiziologi \n",
      "asosi nima ekanligi, unda miyaning roli haqida batafsil \n",
      "soâ€˜zlayman. Qolaversa, yolgâ€˜onni aniqlash usuli haqiÂ­\n",
      "da, -  buni hali FTBning birorta taftish tizimi xodimlari \n",
      "qilgan emas, -  axborot beraman. Men qattiq ishonaman-\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 8\n",
      "Matn:\n",
      " s\n",
      "tana tili yolg'onini aniqlashda ehtiyot boâ€˜lish lozimligini \n",
      "taâ€™kidlab oâ€˜tdi. Bunday belgilarga eâ€™tiborsiz qaraydigan- \n",
      "lar, odatda, bilim, tajribasi kam yoki huquq-tartibot xo- \n",
      "dimlari ichida koâ€˜p uchraydi. Insonni noverbal belgila- \n",
      "riga qarab, Ñ€Ð¾Ðº Ñƒ Ð¾ Ð¿Ð¾Ñ€Ð¾Ðº ekanini aniqlashda oâ€˜ta ehtiyot \n",
      "boâ€˜lish lozim ekanini uqtirdi.\n",
      "Noverbal aloqalar haqidagi taxminiy va shaxsiy maâ€™- \n",
      "lumotlarga suyanib yozilgan boshqa asarlardan farqli \n",
      "ushbu kitob faqat nazariy fikr va tajribada isbotlangan\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 278\n",
      "Matn:\n",
      " chiqarishga juda ehtiyot boâ€˜lish kerak, insonning boshqa \n",
      "aâ€™zolaridagi noverbal ishoralariga suyangan holda xulosa \n",
      "chiqarish lozim.\n",
      "Bundan tashqari, yuzda qulaylik-noqulaylik ifodasiÂ­\n",
      "ni ajratish mushkul. Shu kabi bir necha holatlar mavjud. \n",
      "Agar siz yuz ifodasi nima bildirishiga shubha qilsangiz,\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 308\n",
      "Matn:\n",
      " qisib, qarashlar kiradi. Ifodaviylikni kuchaytirishning \n",
      "yana bir koâ€˜rinishi qiziqishni ifodalovchi gavdani oldin- \n",
      "ga bukishdir. Agar gapning qaysidir qismi ahamiyati,\n",
      "308\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# Savol berish va javob olish\n",
    "input_uzbek = \"Qanday yolgâ€˜onni aniqlash mumkin?\"\n",
    "print(\"â“ Savol:\", input_uzbek)\n",
    "\n",
    "input_english = translate_text(input_uzbek)\n",
    "print(\"ðŸ”„ Ingliz tiliga tarjima:\", input_english)\n",
    "\n",
    "# Javob olish\n",
    "result = qa_chain.invoke({\"query\": input_english})\n",
    "\n",
    "output_english = result[\"result\"]\n",
    "# print(\"ðŸ”„ Javob ingliz tilida:\", output_english)\n",
    "print(\"-\"*50)\n",
    "output_uzbek = translate_text(output_english, source='en', target='uz')\n",
    "print(\"ðŸ¤– Javob o'zbek tilida:\\n\", output_uzbek)\n",
    "\n",
    "print(\"\\nðŸ“– Manbalar:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"Fayl:\", doc.metadata[\"source\"])\n",
    "    print(\"Sahifa:\", doc.metadata.get(\"page\", \"Nomaâ€™lum\"))\n",
    "    print(\"Matn:\\n\", doc.page_content)\n",
    "    print(\"------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
