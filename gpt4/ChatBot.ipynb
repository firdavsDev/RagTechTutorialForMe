{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564bca8e",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai faiss-cpu tiktoken sentence-transformers PyMuPDF ipywidgets deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2baf2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f5d5e",
   "metadata": {},
   "source": [
    "# PDF faylni yuklab, hujjatni chunklash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d2c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 ta sahifa yuklandi.\n",
      "JO N A V A R R O\n",
      "SIZ\n",
      "NIMANI 0‘YLASANGIZ\n",
      "MEN\n",
      "0‘SHANI KO'RAMAN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 PDF faylni yuklash va matnga aylantirish\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PDF fayl nomi\n",
    "pdf_path = \"data/book_1.pdf\"\n",
    "\n",
    "# Hujjatni yuklash\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"{len(documents)} ta sahifa yuklandi.\")\n",
    "print(documents[0].page_content[:300])  # 1-sahifadan parchani chiqaramiz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8a62cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132 ta chunk tayyor bo‘ldi.\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Chunklash (matnni bo‘laklarga ajratish)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Chunking parametrlar\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"{len(chunks)} ta chunk tayyor bo‘ldi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e05344",
   "metadata": {},
   "source": [
    "# Embedding + FAISS Index yaratish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0af975a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Embedding modelini chaqirish\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedding modeli\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    # model_name=\"intfloat/multilingual-e5-small\"\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" \n",
    ") #or sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "# --------------- Ollama Embeddings ----------------\n",
    "# Agar Ollama embeddings ishlatmoqchi bo'lsangiz, quyidagi kodni\n",
    "# faqat Ollama o'rnatilgan bo'lsa ishlating:\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d45c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 FAISS bazaga joylash\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# FAISS vektor bazasini yaratish\n",
    "vector_db = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# Localga saqlash (keyingi bosqichda foydalanamiz)\n",
    "vector_db.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770bcc8b",
   "metadata": {},
   "source": [
    "# Retrieverni sozlash va LLM bilan birlashtirish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da4c7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 FAISS index’ni yuklash\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Oldin saqlangan bazani yuklaymiz\n",
    "vector_db = FAISS.load_local(\"faiss_index\", embedding_model)\n",
    "\n",
    "# Retriever obyektini yasaymiz\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 OpenAI LLM modelini sozlash\n",
    "\n",
    "# from langchain.llms import OpenAI\n",
    "\n",
    "# import os\n",
    "\n",
    "# # OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-***\"  # <-- bu yerga o‘zingizning API key’ingizni qo‘ying. (pullik)\n",
    "\n",
    "# # LLM ni ishga tushuramiz (GPT-3.5)\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# -------------------- Agar Ollama ishlatmoqchi bo'lsangiz --------------------\n",
    "# Ollama modelini yuklab olish\n",
    "# ollama run llama3 or (mistral)\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ded6e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template=\"\"\"\n",
    "You are an intelligent AI assistant helping a user who speaks English.\n",
    "The user will ask you a question, and you should provide a clear, concise, and reliable answer based on the following context.\n",
    "Answer the question based only on the context below.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "📚 Context:\n",
    "{context}\n",
    "\n",
    "❓ Question: {question}\n",
    "\n",
    "🤖 Answer:\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d43ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CombineDocumentsChain ichida ishlat\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "qa_prompt_chain = LLMChain(llm=llm, prompt=custom_prompt)\n",
    "\n",
    "combine_docs_chain = StuffDocumentsChain(\n",
    "    llm_chain=qa_prompt_chain,\n",
    "    document_variable_name=\"context\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c815ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 RAG chain yaratamiz\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     retriever=retriever,\n",
    "#     return_source_documents=True\n",
    "# )\n",
    "\n",
    "qa_chain = RetrievalQA(\n",
    "    retriever=retriever,\n",
    "    combine_documents_chain=combine_docs_chain,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b822603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translator\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_text(txt_input, source='uz', target='en'):\n",
    "    \"\"\"\n",
    "    Translate text from Uzbek to English.\n",
    "    \"\"\"\n",
    "    input_english = GoogleTranslator(source=source, target=target).translate(txt_input)\n",
    "    return input_english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f76dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❓ Savol: Qanday yolg‘onni aniqlash mumkin?\n",
      "🔄 Ingliz tiliga tarjima: What lies can be determined?\n",
      "--------------------------------------------------\n",
      "🤖 Javob o'zbek tilida:\n",
      "\n",
      " Taqdim etilgan kontekst asosida, matn yolg'on va yolg'onni aniqlash usullarini muhokama qilmoqda. Muallif kimningdir haqiqatni aytayotgan yoki yo'qligini aniqlashga urinayotganda noilojma inshootlari va xatti-harakatlariga e'tibor berish muhimligini ta'kidlaydi.\n",
      "\n",
      "Shu nuqtai nazardan, sizning savolingizga javob: \"Yolgun Fosh Qiluvchi Savollar Berish Kerak\" deb tarjima qilinadi, bu \"siz yolg'onni ochib beradigan savollarni berishingiz kerak\" deb tarjima qilinadi.\n",
      "\n",
      "📖 Manbalar:\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 63\n",
      "Matn:\n",
      " qilish yoki aytilmay yashirishga harakat qilinayotgan \n",
      "xabami aniqlashda yordam beradi.\n",
      "Mening fikrimcha, haqqoniy ma’lumot olishga uri- \n",
      "nishdan ko‘ra, tinchlantiruvchi harakatni kuzatish ter-\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 288\n",
      "Matn:\n",
      " kuzatish kerak.\n",
      "Yolg‘onni fosh qiluvchi savollar berish kerak. Bundan \n",
      "tashqari, imkoni boricha noverbal xabarlami ko‘proq \n",
      "yig‘ishingiz kerak. Siz qancha atvor bog‘lanishlarini topa \n",
      "olsangiz, kuzatishingiz natijasida shuncha ishonch komil\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 35\n",
      "Matn:\n",
      " uchun nimaga e’tibor qilish zarurligini anglab yetasiz. \n",
      "Bundan foydalanib, oila a’zolaringiz, sevimli inson, hat­\n",
      "to begona kishini ham oldindan o‘qiy olishingiz mumkin \n",
      "bo‘ladi. Bundan tashqari, noverbal atvoming fiziologi \n",
      "asosi nima ekanligi, unda miyaning roli haqida batafsil \n",
      "so‘zlayman. Qolaversa, yolg‘onni aniqlash usuli haqi­\n",
      "da, -  buni hali FTBning birorta taftish tizimi xodimlari \n",
      "qilgan emas, -  axborot beraman. Men qattiq ishonaman-\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 8\n",
      "Matn:\n",
      " s\n",
      "tana tili yolg'onini aniqlashda ehtiyot bo‘lish lozimligini \n",
      "ta’kidlab o‘tdi. Bunday belgilarga e’tiborsiz qaraydigan- \n",
      "lar, odatda, bilim, tajribasi kam yoki huquq-tartibot xo- \n",
      "dimlari ichida ko‘p uchraydi. Insonni noverbal belgila- \n",
      "riga qarab, рок у о порок ekanini aniqlashda o‘ta ehtiyot \n",
      "bo‘lish lozim ekanini uqtirdi.\n",
      "Noverbal aloqalar haqidagi taxminiy va shaxsiy ma’- \n",
      "lumotlarga suyanib yozilgan boshqa asarlardan farqli \n",
      "ushbu kitob faqat nazariy fikr va tajribada isbotlangan\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 278\n",
      "Matn:\n",
      " chiqarishga juda ehtiyot bo‘lish kerak, insonning boshqa \n",
      "a’zolaridagi noverbal ishoralariga suyangan holda xulosa \n",
      "chiqarish lozim.\n",
      "Bundan tashqari, yuzda qulaylik-noqulaylik ifodasi­\n",
      "ni ajratish mushkul. Shu kabi bir necha holatlar mavjud. \n",
      "Agar siz yuz ifodasi nima bildirishiga shubha qilsangiz,\n",
      "------\n",
      "Fayl: data/book_2.pdf\n",
      "Sahifa: 308\n",
      "Matn:\n",
      " qisib, qarashlar kiradi. Ifodaviylikni kuchaytirishning \n",
      "yana bir ko‘rinishi qiziqishni ifodalovchi gavdani oldin- \n",
      "ga bukishdir. Agar gapning qaysidir qismi ahamiyati,\n",
      "308\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# Savol berish va javob olish\n",
    "input_uzbek = \"Qanday yolg‘onni aniqlash mumkin?\"\n",
    "print(\"❓ Savol:\", input_uzbek)\n",
    "\n",
    "input_english = translate_text(input_uzbek)\n",
    "print(\"🔄 Ingliz tiliga tarjima:\", input_english)\n",
    "\n",
    "# Javob olish\n",
    "result = qa_chain.invoke({\"query\": input_english})\n",
    "\n",
    "output_english = result[\"result\"]\n",
    "# print(\"🔄 Javob ingliz tilida:\", output_english)\n",
    "print(\"-\"*50)\n",
    "output_uzbek = translate_text(output_english, source='en', target='uz')\n",
    "print(\"🤖 Javob o'zbek tilida:\\n\", output_uzbek)\n",
    "\n",
    "print(\"\\n📖 Manbalar:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"Fayl:\", doc.metadata[\"source\"])\n",
    "    print(\"Sahifa:\", doc.metadata.get(\"page\", \"Noma’lum\"))\n",
    "    print(\"Matn:\\n\", doc.page_content)\n",
    "    print(\"------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
