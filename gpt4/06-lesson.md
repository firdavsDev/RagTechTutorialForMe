## ğŸ§  6â€“Dars: Retriever va Generatorâ€™ni Ulaymiz â€” Prompting, Chunking, Context Injection

---

### ğŸ¯ Maqsad:

* Retriever topgan maâ€™lumotni modelga qanday qilib **samarali tarzda uzatish**ni oâ€˜rganish
* **Prompt dizayni**, **context injection**, va **chunking strategiyalari** bilan tanishish
* Real chatbotlar va QA systemalarda nima ishlaydi, nima ishlamaydi â€” bilib olish

---

## ğŸ”— 1. Retriever â†’ Generator ulanishi

RAG arxitekturasi boâ€˜yicha:

```mermaid
graph TD
    A[User query] --> B[Retriever]
    B --> C[Top-k docs]
    C --> D[Prompt constructor]
    D --> E[Generator (e.g., GPT)]
    E --> F[Answer]
```

### âš ï¸ Asosiy muammo:

* LLMâ€™lar (GPT, T5) **konkret input uzunligi bilan cheklangan** (`context window`, masalan: GPT-4 = \~32K token)
* Bizda esa koâ€˜p hujjatlar boâ€˜lishi mumkin

Shuning uchun biz **chunking + prompt design** strategiyalarini ishlatamiz.

---

## âœ‚ï¸ 2. Chunking strategiyalari

### ğŸ”¸ Nima bu â€œchunkingâ€?

Katta hujjatlarni kichik boâ€˜laklarga boâ€˜lib, retrieval va generation bosqichida **token cheklovlariga moslab** ishlatish.

### ğŸŒŸ Eng koâ€˜p ishlatiladigan strategiyalar:

| Nomi                | Tavsifi                                                  |
| ------------------- | -------------------------------------------------------- |
| **Fixed-size**      | Har chunk 512/1024 token                                 |
| **Sliding window**  | Har chunk 70% avvalgisini oâ€˜z ichiga oladi (overlap)     |
| **Semantic split**  | Matnni sentence/topic asosida boâ€˜lish                    |
| **Recursive split** | Paragraph â†’ sentence â†’ token tarzida sekin-sekin boâ€˜lish |

### ğŸ“Œ Python (LangChain bilan chunking):

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_text(large_document)
```

---

## âœï¸ 3. Prompt Dizayni (Prompt Engineering)

Prompt â€” bu generator modelga beriladigan **matnli kontekst + savol**.

### ğŸ“˜ Prompt strukturasi:

```text
Answer the following question based on the documents provided.

Context:
- {doc_1}
- {doc_2}
- ...
- {doc_k}

Question: {user_query}
Answer:
```

### ğŸ“ˆ Yaxshi promptlar:

* Relevant hujjatlarni tartibli beradi (avval eng dolzari)
* Har bir hujjatni cheklangan token miqdorida tozalab beradi
* Tokenlarni behuda isrof qilmaydi (noisy matnni olib tashlaydi)

### ğŸ‘¨â€ğŸ’» Prompt Template misoli (Python):

```python
prompt_template = f"""
You are a helpful assistant.

Use the following context to answer the question:
{retrieved_docs}

Question: {query}
Answer:"""
```

---

## ğŸ§  4. Context Injection â€” Smart Strategy

Koâ€˜p holatda, 3â€“5 hujjat yetarli boâ€˜ladi. Lekin agar hujjatlar koâ€˜p boâ€˜lsa:

* **Top-N** tanlash: faqat eng relevant 3â€“5 hujjatni ol
* **Dynamic reranking**: retriever natijalarini score asosida tartibla
* **Max token limit**: har hujjatdan faqat 400â€“500 token kesib ol

---

## ğŸ”„ Advanced: Iterative RAG

1. Prompt 1 â†’ javob topilmadi
2. Rewriting query (e.g., "rephrase") + new retrieval
3. Final generation

Bunday oqim â€œmulti-hop reasoningâ€ uchun ishlatiladi (LangChainâ€™dagi `Refine`, `MapReduce` flow).

---

## âœ… Uyga vazifa:

1. `RecursiveCharacterTextSplitter` bilan PDF matnni chunklab koâ€˜r.
2. Har bir chunkni embedding qilib FAISS index yarat.
3. Soâ€˜rovga relevant chunklarni olib, GPT prompt tuzib, test qil.

---
