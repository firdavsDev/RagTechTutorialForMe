
## ğŸ§  5â€“Dars: Dense vs Sparse Retrieval â€” FAISS, BM25, ScaNN va boshqalar

---

### ğŸ¯ Maqsad:

* Retrievalning ikki asosiy turi â€” Sparse va Dense haqida chuqur tushunish
* Ularning farqlari, kuchli va zaif tomonlarini oâ€˜rganish
* Qaysi vector search vositalari qanday ishlashini bilish

---

### ğŸ” Retrieval nima?

Retriever â€” foydalanuvchi soâ€˜rovi asosida maâ€™lumotlar bazasidan **eng mos hujjatlarni topib beradigan** mexanizm.

U ikki turga boâ€˜linadi:

| Turi       | Tushuntiruvchi nomlar                  |
| ---------- | -------------------------------------- |
| **Sparse** | Term-based search (e.g., BM25, TF-IDF) |
| **Dense**  | Semantic search (e.g., BERT + FAISS)   |

---

## ğŸ“Œ 1. Sparse Retrieval

**Asos:** Soâ€˜zlar (term) oâ€˜z-oâ€˜zini ifodalaydi. Hech qanday semantik maâ€™no yoâ€˜q.
ğŸ§  Model yod olmaydi â€” bu klassik â€œkeyword matchâ€.

### ğŸŒŸ Mashhur algoritmlar:

* `BM25` (Best Matching 25) â€” TF-IDFning optimized versiyasi

### â• Yaxshi tomonlari:

* Juda tez
* Oson sozlanadi
* Toâ€˜gâ€˜ridan-toâ€˜gâ€˜ri matnga mos keladi (agar exact keyword boâ€˜lsa)

### â– Yomon tomonlari:

* Sinonim, semantik, kontekstni tushunmaydi
* Soâ€˜zlar shakli oâ€˜zgarsa, tushunmaydi
* Oâ€˜zbek tilida yaxshi ishlashi qiyin (lemmatization yetishmaydi)

### ğŸ‘¨â€ğŸ’» Pythonâ€™da BM25:

```python
from rank_bm25 import BM25Okapi

tokenized_corpus = [doc.split() for doc in documents]
bm25 = BM25Okapi(tokenized_corpus)
scores = bm25.get_scores(query.split())
```

---

## ğŸ“Œ 2. Dense Retrieval

**Asos:** Matn semantikasini embedding vektorga aylantirib, oâ€˜xshashlikka qarab qidiradi.

### ğŸŒŸ Mashhur retriever arxitekturalari:

* `DPR` (Dense Passage Retrieval, Facebook)
* `Contriever`, `ColBERT`, `GTR`, `MiniLM`, `MPNet`

### â• Yaxshi tomonlari:

* Sinonimlar, semantik oâ€˜xshashlikni tushunadi
* Har xil tilda juda yaxshi ishlaydi
* Zero-shot / multilingual koâ€˜rinishda ishlaydi

### â– Yomon tomonlari:

* Trening kerak (yoki pre-trained model kerak)
* Vector bazani qurish va xizmat qilish biroz murakkab
* Faiss/Pinecone kabi backendlar kerak

### ğŸ‘¨â€ğŸ’» Pythonâ€™da Dense Retrieval (SentenceTransformers + FAISS):

```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')
corpus_embeddings = model.encode(documents)
index = faiss.IndexFlatL2(corpus_embeddings.shape[1])
index.add(np.array(corpus_embeddings))

query_vector = model.encode(["your query"])
D, I = index.search(np.array([query_vector]), k=5)
```

---

## ğŸ¥Š Dense vs Sparse â€” Taqqoslash

| Xususiyat                   | Sparse (BM25) | Dense (DPR, Faiss)               |
| --------------------------- | ------------- | -------------------------------- |
| Training kerakmi?           | Yoâ€˜q          | Ha / Pretrained                  |
| Sinonim tushunadimi?        | Yoâ€˜q          | Ha                               |
| Speed                       | Tez           | Sekinroq, ammo indexing mumkin   |
| Lokal soâ€˜zlar bilan ishlash | Zoâ€˜r          | Yaxshi, lekin tokenization muhim |
| Index narxi                 | Juda arzon    | Biroz qimmat (vektorli)          |

---

## ğŸ”§ Dense Retrieval uchun mashhur vositalar

| Vosita       | Tavsifi                                         |
| ------------ | ----------------------------------------------- |
| **FAISS**    | Facebook tomonidan yaratilgan, GPU-ni qoâ€˜llaydi |
| **ScaNN**    | Google dan â€” scalable va tez, hybrid dense      |
| **Annoy**    | Spotify dan, RAM-da ishlaydi, minimal setup     |
| **Qdrant**   | Rust asosidagi vector DB, REST API bor          |
| **Pinecone** | SaaS â€” tayyor platforma                         |
| **Weaviate** | Semantic + graph, local & cloud                 |

---

## ğŸš€ Advanced Kombinatsiyalar

### ğŸ”€ Hybrid Retrieval

Sparse + Dense natijalarini birga ishlatish:

* `BM25 + Dense`
* `Weighted ensemble`: scorelarni birlashtirib top N olasan

### ğŸ” Feedback loop bilan fine-tune

* Foydalanuvchi javob bergan feedback asosida retrieverâ€™ni yaxshilash

---

### âœ… Uyga vazifa:

1. HuggingFaceâ€™dan `sentence-transformers/all-mpnet-base-v2` ni ishlatib FAISS index qur.
2. `rank_bm25` bilan natijani solishtir.
3. `retrieval hybrid strategy` haqida maqola oâ€˜qib chiq (HuggingFace blogda bor).
